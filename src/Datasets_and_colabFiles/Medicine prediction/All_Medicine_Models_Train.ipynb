{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dc-7AhNhk_lr"
      },
      "outputs": [],
      "source": [
        "# Cell 1 — Imports & settings\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "ARTIFACTS_DIR = \"artifacts_models\"\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Dataset paths (change if files in different folder)\n",
        "datasets = {\n",
        "    \"allopathy\": \"allopathy_clean.csv\",\n",
        "    \"ayurveda\":  \"ayurveda_clean.csv\",\n",
        "    \"homeopathy\":\"homeopathy_clean.csv\"\n",
        "}\n",
        "\n",
        "print(\"Will train models for these datasets:\")\n",
        "for name, path in datasets.items():\n",
        "    print(f\" - {name}: {path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxrFSjoAlGd4",
        "outputId": "a4a559ed-9a66-48c5-e5a4-164fba06ab60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will train models for these datasets:\n",
            " - allopathy: allopathy_clean.csv\n",
            " - ayurveda: ayurveda_clean.csv\n",
            " - homeopathy: homeopathy_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 — Define a function that trains for a single dataset and saves artifacts\n",
        "def train_and_save_for_dataset(name, csv_path):\n",
        "    print(f\"\\n=== Processing: {name} ===\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(\"Loaded shape:\", df.shape)\n",
        "\n",
        "    # Keep a display lookup table (unique medicine -> display info)\n",
        "    lookup_cols = [\"Medicine_Name\",\"Dosage_Form\",\"Recommended_Dosage\",\"Treatment_Duration\",\"Precautions\",\"Medicine_Approval_Status\"]\n",
        "    lookup = df[lookup_cols].drop_duplicates(subset=[\"Medicine_Name\"]).reset_index(drop=True)\n",
        "\n",
        "    # FEATURES and TARGET (final chosen features)\n",
        "    X = df[[\"Disease_Name\",\"Disease_Severity\",\"Age_Group\"]].astype(str)  # all as strings\n",
        "    y = df[\"Medicine_Name\"].astype(str)\n",
        "\n",
        "    # Encode target (Medicine_Name) with LabelEncoder and save it\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "\n",
        "    # Preprocessor:\n",
        "    # - OneHot for Disease_Name and Age_Group (nominal)\n",
        "    # - OrdinalEncoder for Disease_Severity with explicit order\n",
        "    severity_order = [[\"Mild\",\"Moderate\",\"Severe\"]]\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers = [\n",
        "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"Disease_Name\",\"Age_Group\"]),\n",
        "            (\"ord\", OrdinalEncoder(categories=severity_order), [\"Disease_Severity\"])\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    # Candidate models (you can add/tune more)\n",
        "    models = {\n",
        "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=RANDOM_STATE),\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
        "        \"NaiveBayes\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    # Create X_transformed for CV evaluation (we'll use pipeline inside CV)\n",
        "    # Split into train/test (stratify by encoded target)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.20, random_state=RANDOM_STATE, stratify=y_enc)\n",
        "    print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "    # Cross-validate candidates on training set\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "    cv_scores = {}\n",
        "    for mname, m in models.items():\n",
        "        pipe = Pipeline([(\"preproc\", preprocessor), (\"model\", m)])\n",
        "        try:\n",
        "            scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "            cv_scores[mname] = scores\n",
        "            print(f\"{mname:12s} CV mean: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{mname:12s} ERROR during CV: {e}\")\n",
        "\n",
        "    # Select best model by mean CV accuracy\n",
        "    best_name = max(cv_scores.items(), key=lambda x: x[1].mean())[0]\n",
        "    print(\"Selected best model (by CV mean):\", best_name)\n",
        "    best_model = models[best_name]\n",
        "\n",
        "    # # Fit pipeline on full training data\n",
        "    # final_pipe = Pipeline([(\"preproc\", preprocessor), (\"model\", best_model)])\n",
        "    # final_pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Optional: fine-tune before final fit\n",
        "    final_pipe = tune_model(best_name, preprocessor, X_train, y_train)\n",
        "    if final_pipe is None:\n",
        "        final_pipe = Pipeline([(\"preproc\", preprocessor), (\"model\", models[best_name])])\n",
        "        final_pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = final_pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Test accuracy for {name}: {acc:.4f}\")\n",
        "    print(\"Classification report (test):\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    # Save artifacts: pipeline (includes preprocessor & model), label encoder, lookup\n",
        "    model_file = os.path.join(ARTIFACTS_DIR, f\"model_{name}.pkl\")\n",
        "    le_file = os.path.join(ARTIFACTS_DIR, f\"label_encoder_{name}.pkl\")\n",
        "    preproc_file = os.path.join(ARTIFACTS_DIR, f\"preprocessor_{name}.pkl\")\n",
        "    lookup_file = os.path.join(ARTIFACTS_DIR, f\"lookup_{name}.pkl\")\n",
        "\n",
        "    # Save whole pipeline (preprocessor + model) for easy inference\n",
        "    joblib.dump(final_pipe, model_file)\n",
        "    # Save preprocessor separately too (in case you want only preprocessing)\n",
        "    joblib.dump(preprocessor, preproc_file)\n",
        "    # Save label encoder for decoding predicted class index -> medicine name\n",
        "    joblib.dump(le, le_file)\n",
        "    # Save lookup table for display information\n",
        "    joblib.dump(lookup, lookup_file)\n",
        "\n",
        "    print(\"Saved artifacts:\")\n",
        "    print(\" - pipeline:\", model_file)\n",
        "    print(\" - preprocessor:\", preproc_file)\n",
        "    print(\" - label encoder:\", le_file)\n",
        "    print(\" - lookup:\", lookup_file)\n",
        "\n",
        "    # Return some useful info\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"best_model\": best_name,\n",
        "        \"test_accuracy\": acc,\n",
        "        \"model_file\": model_file,\n",
        "        \"le_file\": le_file,\n",
        "        \"preproc_file\": preproc_file,\n",
        "        \"lookup_file\": lookup_file\n",
        "    }"
      ],
      "metadata": {
        "id": "5jDhLaQhlP3J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def tune_model(best_name, preprocessor, X_train, y_train):\n",
        "    if best_name == \"XGBoost\":\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=RANDOM_STATE)\n",
        "        param_dist = {\n",
        "            \"n_estimators\": [100, 200, 300],\n",
        "            \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "            \"max_depth\": [3, 4, 5, 6],\n",
        "            \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
        "            \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
        "        }\n",
        "    elif best_name == \"RandomForest\":\n",
        "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "        param_dist = {\n",
        "            \"n_estimators\": [100, 200, 300, 500],\n",
        "            \"max_depth\": [5, 10, 15, None],\n",
        "            \"min_samples_split\": [2, 5, 10],\n",
        "            \"min_samples_leaf\": [1, 2, 4],\n",
        "            \"bootstrap\": [True, False]\n",
        "        }\n",
        "    else:\n",
        "        print(\"No tuning configured for this model:\", best_name)\n",
        "        return None\n",
        "\n",
        "    pipe = Pipeline([(\"preproc\", preprocessor), (\"model\", model)])\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=pipe,\n",
        "        param_distributions={\"model__\" + k: v for k, v in param_dist.items()},\n",
        "        n_iter=25,\n",
        "        cv=5,\n",
        "        scoring=\"accuracy\",\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", search.best_params_)\n",
        "    print(\"Best cross-val accuracy:\", search.best_score_)\n",
        "    return search.best_estimator_\n"
      ],
      "metadata": {
        "id": "mNWozco9nwrF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 — Execute training for each dataset and collect results\n",
        "results = {}\n",
        "for sys_name, csv_path in datasets.items():\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"{csv_path} not found in working directory.\")\n",
        "    res = train_and_save_for_dataset(sys_name, csv_path)\n",
        "    results[sys_name] = res\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n=== Summary ===\")\n",
        "for name, info in results.items():\n",
        "    print(f\"{name}: model={info['best_model']}, test_acc={info['test_accuracy']:.4f}, model_file={info['model_file']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCxb6tfzlSW-",
        "outputId": "7329ec68-650a-4809-eb65-f0b43a6874d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing: allopathy ===\n",
            "Loaded shape: (1100, 9)\n",
            "Train/Test sizes: (880, 3) (220, 3)\n",
            "XGBoost      CV mean: 0.6966 ± 0.0099\n",
            "RandomForest CV mean: 0.6898 ± 0.0085\n",
            "KNN          CV mean: 0.6920 ± 0.0174\n",
            "NaiveBayes   CV mean: 0.4011 ± 0.0464\n",
            "Selected best model (by CV mean): XGBoost\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "Best parameters: {'model__subsample': 0.9, 'model__n_estimators': 200, 'model__max_depth': 6, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.8}\n",
            "Best cross-val accuracy: 0.7090909090909092\n",
            "Test accuracy for allopathy: 0.7136\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.71      1.00      0.83        17\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.75      1.00      0.86        18\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.64      1.00      0.78        16\n",
            "           9       0.73      1.00      0.84        16\n",
            "          10       0.00      0.00      0.00         4\n",
            "          11       0.00      0.00      0.00         4\n",
            "          12       0.00      0.00      0.00         6\n",
            "          13       0.00      0.00      0.00         3\n",
            "          14       0.00      0.00      0.00         4\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         4\n",
            "          18       0.00      0.00      0.00         4\n",
            "          19       0.78      1.00      0.88        18\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.71      1.00      0.83        15\n",
            "          22       0.68      1.00      0.81        15\n",
            "          23       0.00      0.00      0.00         2\n",
            "          24       0.67      1.00      0.80        14\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         5\n",
            "          28       0.68      1.00      0.81        13\n",
            "          29       0.79      1.00      0.88        15\n",
            "\n",
            "    accuracy                           0.71       220\n",
            "   macro avg       0.24      0.33      0.28       220\n",
            "weighted avg       0.51      0.71      0.60       220\n",
            "\n",
            "Saved artifacts:\n",
            " - pipeline: artifacts_models/model_allopathy.pkl\n",
            " - preprocessor: artifacts_models/preprocessor_allopathy.pkl\n",
            " - label encoder: artifacts_models/label_encoder_allopathy.pkl\n",
            " - lookup: artifacts_models/lookup_allopathy.pkl\n",
            "\n",
            "=== Processing: ayurveda ===\n",
            "Loaded shape: (1100, 9)\n",
            "Train/Test sizes: (880, 3) (220, 3)\n",
            "XGBoost      CV mean: 0.6852 ± 0.0117\n",
            "RandomForest CV mean: 0.6807 ± 0.0181\n",
            "KNN          CV mean: 0.6500 ± 0.0408\n",
            "NaiveBayes   CV mean: 0.2920 ± 0.0381\n",
            "Selected best model (by CV mean): XGBoost\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "Best parameters: {'model__subsample': 0.8, 'model__n_estimators': 200, 'model__max_depth': 5, 'model__learning_rate': 0.01, 'model__colsample_bytree': 0.7}\n",
            "Best cross-val accuracy: 0.7\n",
            "Test accuracy for ayurveda: 0.7000\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.67      1.00      0.80        16\n",
            "           5       0.68      1.00      0.81        15\n",
            "           6       0.76      1.00      0.86        19\n",
            "           7       0.73      0.73      0.73        22\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.00      0.00      0.00         5\n",
            "          10       0.00      0.00      0.00         2\n",
            "          11       0.00      0.00      0.00         4\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       0.00      0.00      0.00         4\n",
            "          14       0.00      0.00      0.00         6\n",
            "          15       0.73      1.00      0.84        16\n",
            "          16       0.00      0.00      0.00         3\n",
            "          17       0.00      0.00      0.00         4\n",
            "          18       0.69      1.00      0.81        57\n",
            "          19       0.68      0.79      0.73        19\n",
            "          20       0.00      0.00      0.00         3\n",
            "          21       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.70       220\n",
            "   macro avg       0.22      0.30      0.25       220\n",
            "weighted avg       0.52      0.70      0.60       220\n",
            "\n",
            "Saved artifacts:\n",
            " - pipeline: artifacts_models/model_ayurveda.pkl\n",
            " - preprocessor: artifacts_models/preprocessor_ayurveda.pkl\n",
            " - label encoder: artifacts_models/label_encoder_ayurveda.pkl\n",
            " - lookup: artifacts_models/lookup_ayurveda.pkl\n",
            "\n",
            "=== Processing: homeopathy ===\n",
            "Loaded shape: (1100, 9)\n",
            "Train/Test sizes: (880, 3) (220, 3)\n",
            "XGBoost      CV mean: 0.6830 ± 0.0127\n",
            "RandomForest CV mean: 0.6864 ± 0.0141\n",
            "KNN          CV mean: 0.6716 ± 0.0220\n",
            "NaiveBayes   CV mean: 0.3159 ± 0.0171\n",
            "Selected best model (by CV mean): RandomForest\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "Best parameters: {'model__n_estimators': 200, 'model__min_samples_split': 10, 'model__min_samples_leaf': 1, 'model__max_depth': 5, 'model__bootstrap': True}\n",
            "Best cross-val accuracy: 0.7113636363636364\n",
            "Test accuracy for homeopathy: 0.7000\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         7\n",
            "           1       0.62      0.75      0.68        20\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.71      1.00      0.83        15\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.61      0.69      0.65        16\n",
            "           6       0.76      1.00      0.86        51\n",
            "           7       0.00      0.00      0.00        12\n",
            "           8       0.00      0.00      0.00         3\n",
            "           9       0.71      1.00      0.83        15\n",
            "          10       0.00      0.00      0.00         3\n",
            "          11       0.65      0.65      0.65        23\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.00      0.00      0.00         3\n",
            "          15       0.00      0.00      0.00         3\n",
            "          16       0.70      1.00      0.82        32\n",
            "          17       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.70       220\n",
            "   macro avg       0.27      0.34      0.30       220\n",
            "weighted avg       0.54      0.70      0.61       220\n",
            "\n",
            "Saved artifacts:\n",
            " - pipeline: artifacts_models/model_homeopathy.pkl\n",
            " - preprocessor: artifacts_models/preprocessor_homeopathy.pkl\n",
            " - label encoder: artifacts_models/label_encoder_homeopathy.pkl\n",
            " - lookup: artifacts_models/lookup_homeopathy.pkl\n",
            "\n",
            "=== Summary ===\n",
            "allopathy: model=XGBoost, test_acc=0.7136, model_file=artifacts_models/model_allopathy.pkl\n",
            "ayurveda: model=XGBoost, test_acc=0.7000, model_file=artifacts_models/model_ayurveda.pkl\n",
            "homeopathy: model=RandomForest, test_acc=0.7000, model_file=artifacts_models/model_homeopathy.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 — Example: load the allopathy pipeline and label encoder and test a few samples\n",
        "from pprint import pprint\n",
        "\n",
        "# change 'allopathy' to any of 'ayurveda' or 'homeopathy' to test others\n",
        "sys_to_test = \"homeopathy\"\n",
        "\n",
        "pipe = joblib.load(os.path.join(ARTIFACTS_DIR, f\"model_{sys_to_test}.pkl\"))\n",
        "le = joblib.load(os.path.join(ARTIFACTS_DIR, f\"label_encoder_{sys_to_test}.pkl\"))\n",
        "lookup = joblib.load(os.path.join(ARTIFACTS_DIR, f\"lookup_{sys_to_test}.pkl\"))\n",
        "\n",
        "samples = [\n",
        "    {\"Disease_Name\":\"Fever\", \"Disease_Severity\":\"Moderate\", \"Age_Group\":\"Adult\"},\n",
        "    {\"Disease_Name\":\"Asthma\", \"Disease_Severity\":\"Severe\", \"Age_Group\":\"Child\"},\n",
        "    {\"Disease_Name\":\"Diabetes\", \"Disease_Severity\":\"Mild\", \"Age_Group\":\"Elderly\"},\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    Xs = pd.DataFrame([s])\n",
        "    pred_enc = pipe.predict(Xs)[0]\n",
        "    pred_med = le.inverse_transform([int(pred_enc)])[0]  # decode\n",
        "    rec = lookup[lookup[\"Medicine_Name\"] == pred_med]\n",
        "    display_info = rec.to_dict(orient=\"records\")[0] if not rec.empty else {}\n",
        "    print(\"Input:\", s)\n",
        "    print(\"Predicted Medicine:\", pred_med)\n",
        "    print(\"Display info (sample):\")\n",
        "    pprint(display_info)\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrgWqjo0lcC0",
        "outputId": "39eee716-d9bd-477c-9a14-e7d67f6f0f44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: {'Disease_Name': 'Fever', 'Disease_Severity': 'Moderate', 'Age_Group': 'Adult'}\n",
            "Predicted Medicine: Belladonna\n",
            "Display info (sample):\n",
            "{'Dosage_Form': 'Syrup',\n",
            " 'Medicine_Approval_Status': 'HPUS Listed',\n",
            " 'Medicine_Name': 'Belladonna',\n",
            " 'Precautions': 'Do not exceed dosage',\n",
            " 'Recommended_Dosage': '1 tsp twice daily',\n",
            " 'Treatment_Duration': 'Continuous'}\n",
            "------------------------------------------------------------\n",
            "Input: {'Disease_Name': 'Asthma', 'Disease_Severity': 'Severe', 'Age_Group': 'Child'}\n",
            "Predicted Medicine: Belladonna\n",
            "Display info (sample):\n",
            "{'Dosage_Form': 'Syrup',\n",
            " 'Medicine_Approval_Status': 'HPUS Listed',\n",
            " 'Medicine_Name': 'Belladonna',\n",
            " 'Precautions': 'Do not exceed dosage',\n",
            " 'Recommended_Dosage': '1 tsp twice daily',\n",
            " 'Treatment_Duration': 'Continuous'}\n",
            "------------------------------------------------------------\n",
            "Input: {'Disease_Name': 'Diabetes', 'Disease_Severity': 'Mild', 'Age_Group': 'Elderly'}\n",
            "Predicted Medicine: Belladonna\n",
            "Display info (sample):\n",
            "{'Dosage_Form': 'Syrup',\n",
            " 'Medicine_Approval_Status': 'HPUS Listed',\n",
            " 'Medicine_Name': 'Belladonna',\n",
            " 'Precautions': 'Do not exceed dosage',\n",
            " 'Recommended_Dosage': '1 tsp twice daily',\n",
            " 'Treatment_Duration': 'Continuous'}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}